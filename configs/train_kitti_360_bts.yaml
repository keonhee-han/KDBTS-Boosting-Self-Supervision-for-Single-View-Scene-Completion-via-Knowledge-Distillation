defaults:
    - default
    - data: kitti_360
    - _self_

name: "kitti_360"
# model: "bts"
output_path: "outputs/bts/kitti_360"

num_epochs: 25
batch_size: 16

save_best:
    metric: abs_rel
    sign: -1

data:
    data_fc: 2
    image_size: [192, 640]
    color_aug: true
    is_preprocessed: true
    fisheye_rotation: [0, -15]

model_conf:
    arch: "BTSNet"
    use_code: true
    prediction_mode: default

    encoder:
        type: "monodepth2"
        freeze: false            # freezing encoder to train the transformer
        pretrained: true
        resnet_layers: 50
        num_ch_dec: [32,32,64,128,256]
        d_out: 64               # c.f. paper D.1. output channel dimension 64 as hparam for the best result

    code:
        num_freqs: 6
        freq_factor: 1.5
        include_input: true

    mlp_coarse:
        type : "resnet"
        n_blocks : 0
        d_hidden : 64

    ids_enc_offset_viz: [0]     # which cam to choose for inference of viz_eval. e.g. [0, 1 ...] or None if you want to sample randomly (c.f. fisheye_offset)
    
    mlp_fine:
        type : "empty"
        n_blocks : 1
        d_hidden : 128

    z_near: 3
    z_far: 80
    inv_z: true

    n_frames_encoder: 1
    n_frames_render: 2
    frame_sample_mode: kitti360-mono

    sample_mode: patch
    patch_size: 8
    ray_batch_size: 4096

    flip_augmentation: true

    learn_empty: false
    code_mode: z

loss:
    criterion: "l1+ssim"
    invalid_policy: weight_guided
    lambda_edge_aware_smoothness: 0.001

scheduler:
    type: step
    step_size: 120000
    gamma: 0.1

renderer:
    n_coarse : 64
    n_fine : 0
    n_fine_depth : 0
    depth_std : 1.0
    sched : []
    white_bkgd : false
    lindisp: true
    hard_alpha_cap: true